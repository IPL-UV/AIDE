# Configuration file
name: 'AIDE'
# Addressed task, choices: Classification, OutlierDetection
task: 'Classification'
# Use a previously saved model to skip train phase
from_scratch: true
# Path to the best model, required if from_scrath: false
best_run_path: ""
# Directory to save model outputs and results
save_path: "experiments/"
# Debug mode: sets inference / xai to only two samples and prints extra info
debug: false

# Database and DataLoader definition
data:
    name: 'DROUGHT' # DROUGHT  DROUGHT1D
    data_dim: 1 # Data dimension
    seed_idx: 1
    root: './databases/Russia/' # Database root  /data/users/ESDL/
    data_file: 'ESDC_RUSSIA.nc' # Data filename
    labels_file: 'GDIS_RUSSIA.nc' # Labels filename
    lat_slice_train: "59, 43" # Max/min latitude coordinates (train)
    lon_slice_train: "30, 60" # Min/max longitude coordinates (train)
    input_size_train: 24 # (256,256,32) # Model input size (lat,lon,time)
    lat_slice_test: "59, 43" # Max/min latitude coordinates (test)
    lon_slice_test: "30, 60"  # Min/max longitude coordinates (test)
    input_size_test: 24  # (256,256,32) # Model output size (lat,lon,time)
    time_slice: "'1-July-2003','December-2013'" # Time interval selected
    features: # ECVs included in the database
        - 'root_moisture'
        - 'air_temperature_2m'
        - 'evaporation'
        - 'transpiration'
    features_selected: [0,1,2,3] # ECVs selected [0,1,2,3]
    # Directory to save climatology mean values
    climatology_mean_root: './databases/Russia/data_py/climatology_mean'
    # Directory to save climatology standard deviation values
    climatology_std_root: './databases/Russia/data_py/climatology_std'
    # Clip values after pre-processing based on climatology
    climatology_clipping: true
    nexp: "1" # Number of experiment to be performed
    # Train, validation and test slices for each experiment
    train_slice:
        exp1:
            - "'1-July-2008','30-June-2010'"
    val_slice:
        exp1:
            - "'1-January-2010','31-December-2010'"
    test_slice:
        exp1:
            - "'1-July-2011','31-December-2012'"
    batch_size: 4096 # Batch size
    num_classes: 2 # Number of categories in the database (drought, non-drought)

# Architecture definition
arch:
    # Select user-defined model (true/false)
    user_defined: True
    # Type of architecture to be used (e.g., 'UNET')
    type: 'UD_LSTM'
    # Parameters to configure the architecture
    params:
        hidden_dim: 128

    # Model input dimension (1: 1D, 2: 2D)
    input_model_dim: 1
    # Model output dimension (1: 1D, 2: 2D)
    output_model_dim: 1

# Definition of the training stage
implementation:
    # Loss function
    loss:
        user_defined: false # Select user-defined model (true/false)
        type: "sigmoid_focal_loss" # Type
        package: 'torchvision.ops' # Package, none for user defined
        activation:
            type: 'linear' # Activation before computing the loss function
        masked: true # Use masks to compute loss true
        # Parameters for the loss function
        params:
            reduction: 'none'
            alpha: 0.5
            gamma: 0
    # Definition of the optimizer
    optimizer:
        type: "Adam" # Optimizer type
        lr: 0.001 # Learning rate 0.0001
        weight_decay: 0 # Weight decay
        gclip_value: 1. # Gradient clipping values
    # Definition of Pytorch trainer
    trainer:
        accelerator: 'gpu' #Pytorch Lightning 2.0
        devices: 1 #Pytorch Lightning 2.0
        epochs: 20 # # Number of epochs
        batch_size: 4096 # Batch size 16
        monitor: # Metric to be monitored during training
            split: 'val'
            metric: 'AUROC'
        monitor_mode: 'max' # Monitor mode (increase or decrease monitored metric value)
        early_stop: 5 # Number of steps to perform early stopping
    # Definition of Pytorch data loader
    data_loader:
        num_workers: 12 # Number of CPUs to read the data in parallel

evaluation:
    test_batch_size: 4096 # Test Batch size 1
    metrics:
        AUROC: {task: 'binary'}
        AveragePrecision: {task: 'binary'}
        F1Score: {task: 'binary'}
        Accuracy: {task: 'binary'}

    visualization:
        activate: false
        params:
            time_aggregation: true # Time aggregation for visualization purposes

    characterization:
        activate: false
        params:
            time_aggregation: true # Time aggregation for characterization purposes
            min_distance: 100 # minimum euclidean distance between pixels to consider two True pixels connected
            remove_scant: false
            min_area_holes: 64
            min_area_objects: 64
            threshold:
                F1Score: {task: 'multiclass', num_classes: 4} # predefined threshold or selected threshold metrics for characterization, 0.5 or 'f1_score'
            threshold_lower_is_best: false

    xai:
        activate: false
        params:
            type: 'InputXGradient' #'IntegratedGradients'
            out_agg_dim: [2,3]
            params: ~
            mask: "events" #One of ["none", "events[-full]", "correctness[-full]", "labels[-full]", "custom[-full]"]
            time_aggregation: true # Time aggregation for characterization purposes
            min_distance: 100 # minimum euclidean distance between pixels to consider two True pixels connected
            remove_scant: false
            min_area_holes: 64
            min_area_objects: 64
            threshold:
                F1Score: {task: 'multiclass', num_classes: 4} # predefined threshold or selected threshold metrics for characterization, 0.5 or 'f1_score'
            threshold_lower_is_best: false
