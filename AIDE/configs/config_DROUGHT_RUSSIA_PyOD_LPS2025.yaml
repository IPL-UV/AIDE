# Configuration file
name: 'AIDE'
# Addressed task, choices: Classification, OutlierDetection
task: 'OutlierDetection'
# Use a previously saved model to skip train phase
from_scratch: true
# Path to the best model, required if from_scrath: false
best_run_path: ""
# Directory to save model outputs and results
save_path: "experiments/" 
# Debug mode: sets inference / xai to only two samples and prints extra info
debug: false

# Database and DataLoader definition
data:
    name: 'DROUGHT'
    data_dim: 3 # Data dimension
    seed_idx: 1
    root: './databases/RussiaLPS2025/' # Database root  /data/users/ESDL/
    data_file: 'ESDC_RUSSIA.nc' # Data filename
    labels_file: 'GDIS_RUSSIA.nc' # Labels filename
    lat_slice_train: "51, 39" # Max/min latitude coordinates (train)
    lon_slice_train: "27.3, 67.3" # Min/max longitude coordinates (train)
    input_size_train: (48,80,1) # (256,256,32) # Model input size (lat,lon,time)
    lat_slice_val: "63, 51" # Max/min latitude coordinates (val)
    lon_slice_val: "27.3, 47.3" # Min/max longitude coordinates (val)
    input_size_val: (48,80,1) # (256,256,32) # Model input size (lat,lon,time)
    lat_slice_test: "63, 51" # Max/min latitude coordinates (test)
    lon_slice_test: "47.3, 67.3"  # Min/max longitude coordinates (test)
    input_size_test: (48,80,1)  # (256,256,32) # Model output size (lat,lon,time)
    time_slice: "'January-2003','December-2012'" # Time interval selected
    features: # ECVs included in the database
        - 'surface_moisture'
        - 'air_temperature_2m'
        - 'evaporation'
        - 'ndvi'
    features_selected: [0,1,2,3] # ECVs selected
    # Directory to save climatology mean values
    climatology_mean_root: './databases/RussiaLPS2025/data_py/climatology_mean'
    # Directory to save climatology standard deviation values
    climatology_std_root: './databases/RussiaLPS2025/data_py/climatology_std'
    # Clip values after pre-processing based on climatology
    climatology_clipping: true
    nexp: "1" # Number of experiment to be performed
    # Train, validation and test slices for each experiment
    train_slice:
        exp1:
            - "'1-January-2003','31-December-2010'"
    val_slice:
        exp1:
            - "'1-January-2003','31-December-2010'"
    test_slice:
        exp1:
            - "'1-January-2009','31-December-2012'"
    batch_size: 1 # Batch size 16
    num_classes: 2 # Number of categories in the database (drought, non-drought)
    n_samples: 1000

# Architecture definition
arch:
    # Select user-defined model (true/false)
    user_defined: False 
    # Type of architecture to be used (e.g., 'UNET')
    type: 'pca.PCA' # "specifies the type of architecture to be used
    # Parameters to configure the architecture (see description in PyOD API)
    args:
        contamination: 0.1
        weighted: true
        whiten: true
        standardization: true
        
    # Model input dimension (1: 1D, 2: 2D)
    input_model_dim: 1
    # Model output dimension (1: 1D, 2: 2D)
    output_model_dim: 1
    # Select 1 out of 100 samples for training or evaluation purposes
    step_samples_train: 10000
    step_samples_evaluation: 2500
    
# Definition of the training stage
implementation:
    # Definition of Pytorch trainer
    trainer:  
        batch_size: 2 # Batch size
    # Definition of Pytorch data loader
    data_loader: 
        num_workers: 12 # Number of CPUs to read the data in parallel

# Visualization
evaluation:  
    metrics:
        roc_auc_score: {probabilities: True}
        accuracy_score: {probabilities: False}
        recall_score: {probabilities: False}
        average_precision_score: {probabilities: False}
        precision_score: {probabilities: False}
        
    visualization:
        activate: true

