# Configuration file
name: 'AIDE'
# Addressed task, choices: Classification, OutlierDetection
task: 'Classification'
# Use a previously saved model to skip train phase
from_scratch: true
# Path to the best model, required if from_scrath: false
best_run_path: ""
# Directory to save model outputs and results
save_path: "experiments/"
# Debug mode: sets inference / xai to only two samples and prints extra info
debug: false

# Database and DataLoader definition
data:
    name: 'XAIDA'
    seed: 42 # Global seed for random draws
    data_dim: 1 # Data dimension
    root: './databases/XAIDA/' # Database root
    index_data: 'index_data/xaida_impacts_disaster_dataframe.csv' # Database folder inside database root
    clim_data: 'clim_data/DB_extreme_clim_events_impacts.zarr/'
    num_classes: 4 # Number of categories
    whole_ts: false
    random_lead_time: -100 #Randomly pick up to random_lead_time in the past as input
    before_event: -100 # How many days in the past as input (default: 180)
    after_event: 25
    steps_per_batch: 'all' #32 # Timesteps per batch
    input_size: 10
    train_slice: 
        start: 1989
        end: 2010
    val_slice:
        start: 2011
        end: 2015
    test_slice:
        start: 2016
        end: 2021

    units: 'normalized-anomalies' # or original
    impact_var: 'normalized_affected'
    extremes:
        - Storm
    continents:
        - Europe
    features: # ECVs included in the database
        - pet
        - pev
        - spei_30
        - spei_90
        - spei_180
        - t2m 
        - t2mmax
        - t2mmin
        - tp
        - smsurf
    features_selected: [0,1,2,3,4,5,6,7,8,9] # ECVs selected

# Architecture definition
arch:
    # Select user-defined model (true/false)
    user_defined: true
    # Type of architecture to be used (e.g., 'UNET')
    type: "UD_LSTM_TS"
    # Parameters to configure the architecture
    params:
        hidden_dim: 150 
        hidden_layers: 2
    # Model input dimension (1: 1D, 2: 2D)
    input_model_dim: 2
    # Model output dimension (1: 1D, 2: 2D)
    output_model_dim: 1

# Definition of the training stage
implementation:
    # Loss function
    loss: 
        user_defined: true # Select user-defined model (true/false)
        type: 'CrossEntropyDiceLoss1D' # Type
        package: 'none' # Package, none for user defined 
        activation: 
            type: 'softmax' # Activation before computing the loss function
        masked: false # Use masks to compute loss
        # Parameters for the loss function
        params:
            lam: 0.05
    # Definition of the optimizer
    optimizer:
        type: "AdamW" # Optimizer type
        lr: 0.0001 # Learning rate
        weight_decay: 0 # Weight decay
        gclip_value: 0 # Gradient clipping values
    
    # Definition of Pytorch trainer
    trainer:  
        accelerator: "cpu" #Pytorch Lightning 2.0
        devices: 1 #Pytorch Lightning 2.0
        epochs: 1000 # Number of epochs 50
        batch_size: 8 # Batch size
        monitor: # Metric to be monitored during training
            split: 'val'
            metric: 'loss' 
        monitor_mode: 'min' # Monitor mode (increase or decrease monitored metric value)
        early_stop: 10 # Number of steps to perform early stopping
    # Definition of Pytorch data loader
    data_loader: 
        num_workers: 16

# Types of chosen evaluations, choices: Visualization, Characterization, XAI
evaluation:
    metrics:
        Accuracy: {task: 'multiclass', num_classes: 4}
        F1Score: {task: 'multiclass', num_classes: 4}
        Precision: {task: 'multiclass', num_classes: 4}
        Recall: {task: 'multiclass', num_classes: 4}
        CohenKappa: {task: 'multiclass', num_classes: 4}
      
    visualization: 
        activate: true
        params:
            time_aggregation: false # Time aggregation for visualization purposes
    
    characterization: 
        activate: true
        params:
            time_aggregation: false # Time aggregation for visualization purposes
            min_distance: 5 # minimum euclidean distance between pixels to consider two True pixels connected 
            threshold: 
                F1Score: {task: 'multiclass', num_classes: 4} # predefined threshold or selected threshold metrics for characterization, 0.5 or 'f1_score'
            threshold_lower_is_best: false
        
    xai:
        activate: true
        params:
            type: 'IntegratedGradients' #'IntegratedGradients'
            params: ~
            out_agg_dim: ~
            mask: 'events' # One of ["none", "events[-full]", "correctness[-full]", "labels[-full]", "custom[-full]"]
            threshold:
                F1Score: {task: 'multiclass', num_classes: 4} # predefined threshold or selected threshold metrics for characterization, 0.5 or 'f1_score'
            threshold_lower_is_best: false
            min_distance: 5 # minimum euclidean distance between pixels to consider two True pixels connected
            time_aggregation: false # Time aggregation for visualization purposes
