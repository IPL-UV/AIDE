# Configuration file
name: 'AIDE'
# Addressed task, choices: Classification, OutlierDetection, ImpactAssessment
task: ...
# Use a previously saved model to skip train phase
from_scratch: ...
# Path to the best model, required if from_scrath: false
best_run_path: ''
# Directory to save model outputs and results
save_path: "experiments/" 
#  Debug mode: sets inference to a specific number of samples and prints extra info. Can be false/true or int
debug: ...

# Database and DataLoader definition
data:
    name: ...
    data_dim: ... # Data dimension
    input_size: ... # Number of features
    features: # Name of the features of the database
    features_selected: ... # Features selected from the whole set of features
    num_classes: ... # Number of categories in the database (drought, non-drought, e.g.)
    time_aggregation: ... # Time aggregation for visualization purposes (true/false)
    lon_slice_test: ... # If visualization 2D enabled, min/max longitude coordinates (test)
    lat_slice_test: ... # If visualization 2D enabled, min/max latitude coordinates (test)

# Architecture definition
arch:
    # Select user-defined model (true/false)
    user_defined: ...
    # Type of architecture to be used (e.g., 'UNET')
    type: ...
    # Parameters to configure the architecture
    params:
        param_1: ...
    # Model input dimension (1: 1D, 2: 2D)
    input_model_dim: ...
    # Model output dimension (1: 1D, 2: 2D)
    output_model_dim: ...

# Definition of the training stage
implementation:
    # Loss function
    loss: 
        user_defined: ... # Select user-defined loss (true/false)
        type: ...  # Specify name of the class loss (e.g. "mse_loss")
        package: ... # Specify loss' package to be imported (e.g."torch.nn.functional"), none for user defined
        activation: ... # Activation before computing the loss function 
        masked: ... # Use masks to compute loss (true/false)
        # Parameters for the loss function
        params:
            reduction: 'none'
            param_1: ...
    # Definition of the optimizer
    optimizer:
        type: ... # Optimizer type
        lr: ... # Learning rate
        weight_decay: ... # Weight decay
        gclip_value: ... # Gradient clipping values
    
    # Definition of Pytorch trainer
    trainer:  
        accelerator: 'gpu' #Pytorch Lightning 2.0
        devices: 1 #Pytorch Lightning 2.0
        epochs: ... # Number of epochs
        batch_size: ... # Batch size
        monitor: # Metric to be monitored during training
            split: ... # Choices: train/val/test
            metric: ... # Either loss or a metric's name to monitor for early stopping and checkpoints
        monitor_mode: ... # Monitor mode (increase or decrease monitored metric value)
        early_stop: ... # Number of steps to perform early stopping
        save_dir: "experiments/" # Directory to save model outputs and results
    # Definition of Pytorch data loader
    data_loader: 
        num_workers: ...

# Types of evaluations, choices: Visualization, Characterization, XAI
evaluation:
    # List of metrics to be computed from torchmetrics
    metrics:
        Metric_1: {param_1: ...} # Metric for evaluation, from torchmetrics. Metric_1 has to be the name of the metric as in torhcmetrics docs
    # Plot of results, available for tasks Classification and OutlierDetection
    visualization: 
        activate: ... # Activate visualization (true/false)
    
    # Characterize the detected event if task is Classification
    characterization:
        activate: ... # Activate characterization (true/false)
        params:
            threshold: ... # Predefined threshold or selected threshold metrics for characterization, 0.5 or 'f1_score'
            threshold_lower_is_best: .. # Threshold metric is better when lower (true/false)
    # Explainability of the trained model
    xai:
        activate: ... # Activate explainability module (true/false)
        params: 
            type: ... # Choose method, must be same name as in Captum docs
            params: ... # Specify method params
            out_agg_dim: ... # Perform output aggregation over the specified dimension
        mask: ... 

